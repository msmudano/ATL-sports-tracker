name: Scrape Atlanta Sports Info

on:
  schedule:
    - cron: '0 9 * * *'  # runs daily at 4am EST
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout repository
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      # 2. Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3. Install Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ./requirements.txt
          pip install selenium

      # 4. Install Google Chrome
      - name: Install Google Chrome
        run: |
          sudo apt update
          sudo apt install -y chromium-browser chromium-chromedriver

      # 5. Install Chromedriver
      - name: Install Chromedriver
        uses: nanasess/setup-chromedriver@v1
        with:
          chrome-version: stable

      # 6. Run Falcons scraper
      - name: Run Falcons scraper
        run: |
          python scraper_falcons.py

      # 7. Run Hawks scraper
      - name: Run Hawks scraper
        run: |
          python scraper_hawks.py

      # 8. Commit & push updated data.json if changed
      - name: Commit & push updated data.json
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          if ! git diff --quiet -- data.json; then
            git add data.json
            git commit -m "Update Falcons and Hawks data"
            git push origin HEAD:main
          else
            echo "No changes detected"
